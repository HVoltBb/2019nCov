# 2019 Novel Coronavirus data analysis (2019新冠病毒数据分析)

## Only one objective: Inferring the underlying number of infected people in Wuhan
## 唯一的目的：推算武汉感染人口的真实数目

### Intro

Chinese people have been suffering from the novel coronavirous (2019nCov) since the end of last year. I hope this epidemic will soon come to an end. Over the years, the government has been known to release creatively engineered data to the public; the public, on the other hand, are well aware of this fact, and have learned to not trust those data. Over these days, I have grown increasingly uncomfortable as what I see from Chinese media is very inconsistent with what I see from those people living in Wuhan. As of 2/2 2020, the number of confirmed infected in Wuhan has grown to 9074 cases according to offical sources. However, I have a gut feeling that the underlying number of infected will far exceed that number from a few reasons, which I will list below as assumptions.

**Assumptions**:
1. The government does not lie, but they may deceive you (A1)
2. Confirming a positive case is limited by various factors (A2)
3. The confirmed case has to go through a series of governmental approval process (A3)

I am confident that these assumptions reflect what is happening based on my own experience and what I read from the Internet (both the censored version and uncensored), but I am open to discussion on those assumptions as well, because my priority here is to reveal the facts. The officially confirmed cases are just the lower bound of the underlying total (A1), and those numbers are time lagged (A3) and capacity limited (A2). For example, only a few state owned hospitals in Wuhan are officailly approved to confirm any cases, public transportation is suspended in Wuhan and according to some sources, those previleged hospitals are only accepting new patients who have shown the most severe symptoms. A patient showing the most severe symptoms have a higher probability of being admitted to a hospital, and those with minor symptoms can only use community clinics and other lower quality hospitals. Hospitals are also limited by their number of beds available, and they are not admitted all the patients. That's why the government is rapid building two new hospitals in Wuhan.

The data quality of the daily confirmed cases are subject to many factors and they may never be good enough for a quantitative dynamical analysis. However, over the last month, I have seen two dynamical epidemiological models, one on [medRxiv](https://doi.org/10.1101/2020.01.23.20018549) and one on [the Lancet](https://doi.org/10.1016/S0140-6736(20)30260-9). Both of them used the same methodology and similar datasets. I don't know who copied whoes idea, but the idea is simple: the official number of infected is only a lower bound on the real number, and you use the international data to get a correction. There are a few limitations to both of those studies. For the medRxiv one, the methods section is not clear on how the ascertain rate is calculated and they used **traffic data from 2017**. For the Lancet one, the method is very clear but the **air traffic data is from last year (Jan-Feb 2019)** as probably the current data are not available yet on OAG. The ascertain rates estimated from those papers are about the same around 5%. **Only around 5% of all the infected people has been officially identified.** 

### Basic idea

We are doing basically the same thing here but using a different set of data, the evacuated foreign nationals from Wuhan. During last week, many countries has performed their evacuation flights using mostly military planes, and those evacuated will be closed monitored. I have compiled the data of evacuated foreign nationals by flights, and the number of infected with each flight. Since these events are relatively new, and many of those evacuated are still kept in quarantine, some of the numbers need to be confirmed in the coming week. For this analysis, we are estimating the spot rate from 1/29-2/2 since those evacuation flights happened closely by each other. If, however, the percentages infected from different flights are dramatically different, a simple ODE model (i.e., SEIR) as used in those two papers would be needed. I should emphasize this: the modeling part is super easy, and it is the data collection and confirmation part that is difficult.

Here, we are using a Bayesian hierarchical model here. It is a hierarchical model, because people from different country would have a different infection rate based on their occupation, life style and race. I choose to use the Bayesian methods just because it is easier to analyze this way. The infection rate of people of nationality *i* <img src="https://latex.codecogs.com/svg.latex?\gamma_i"> is <a href="https://www.codecogs.com/eqnedit.php?latex=\gamma_i&space;\sim&space;Beta(\alpha,&space;1)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\gamma_i&space;\sim&space;Beta(\alpha,&space;1)" title="\gamma_i \sim Beta(\alpha, 4)" /></a>, where the prior distribution of <a href="https://www.codecogs.com/eqnedit.php?latex=\alpha" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\alpha" title="\alpha" /></a> is <a href="https://www.codecogs.com/eqnedit.php?latex=\alpha&space;\sim&space;\text{Uniform}(0.5,&space;1.536)" target="_blank"><img src="https://latex.codecogs.com/gif.latex?\alpha&space;\sim&space;\text{Uniform}(0.5,&space;1.536)" title="\alpha \sim \text{Uniform}(0.5, 1.536)" /></a>. The construction of the prior is based on the regular flu virus, which has with a mean of 20% for unvaccinated person. The number 1.536 was found by numerical optimization through fixing the lower bound of the prior distribution to 0.5 and restricting the mean to 20%. Our prior for the infection rate has a mean at 20% with a 95% CI of (0.36%, 60.81%), which is reasonable for the given case.



